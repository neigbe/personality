{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from data_processing import pers_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = os.environ[\"WORKSPACE_PATH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERS_DATA_FOLDER = f\"{PWD}/data/personality_data/\"\n",
    "\n",
    "in_pers_data = lambda data_path: f\"{PERS_DATA_FOLDER}{data_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_load_json(path, lines=False):\n",
    "    obj = [] if lines else {}\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r+\") as fp:\n",
    "            if lines:\n",
    "                obj += [json.loads(line) for line in fp.readlines()]\n",
    "            else:\n",
    "                obj.update(json.load(fp))\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(path, obj, lines=False):\n",
    "    with open(path, \"w+\") as fp:\n",
    "        if lines:\n",
    "            fp.writelines([json.dumps(item) for item in obj])\n",
    "        else:\n",
    "            json.dump(obj, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percent of movies found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PWD}/data/cornell_movies/speakers.json\", \"r+\") as  fp:\n",
    "    speakers = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = sorted(list({speakers[char][\"meta\"][\"movie_name\"].strip().lower() for char in speakers}))\n",
    "\n",
    "movie_to_id_path = in_pers_data(\"movie_to_id.json\")\n",
    "movie_to_id = open_and_load_json(movie_to_id_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7520259319286872"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_to_id) / len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percent of characters matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_pers_path = in_pers_data(\"char_to_pers_votes.json\")\n",
    "char_to_pers = open_and_load_json(char_to_pers_path)\n",
    "\n",
    "movie_to_chars_path = in_pers_data(\"movie_to_chars.json\")\n",
    "movie_to_chars = open_and_load_json(movie_to_chars_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3775914634146341"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_to_pers) / len([char for movie in movie_to_chars for char in movie_to_chars[movie]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_to_pers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6560"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([char for movie in movie_to_chars for char in movie_to_chars[movie]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.338362068965517"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2477 / 464"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting personality_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_pers = pers_labels.get_pers_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mbpt distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ESFJ': (122, 0.04925312878482035, 0.05367355917289925),\n",
       " 'INFP': (127, 0.051271699636657245, 0.05587329520457545),\n",
       " 'ESFP': (167, 0.06742026645135245, 0.07347118345798505),\n",
       " 'ESTP': (224, 0.0904319741622931, 0.0985481742190937),\n",
       " 'INTJ': (112, 0.04521598708114655, 0.04927408710954685),\n",
       " 'ISTJ': (198, 0.07993540573274122, 0.08710954685437748),\n",
       " 'ISTP': (145, 0.05853855470327009, 0.06379234491860977),\n",
       " 'ENTP': (143, 0.05773112636253532, 0.06291245050593929),\n",
       " 'INTP': (111, 0.04481227291077917, 0.048834139903211615),\n",
       " 'ENFJ': (106, 0.04279370205894227, 0.04663440387153542),\n",
       " 'ISFJ': (171, 0.06903512313282197, 0.075230972283326),\n",
       " 'INFJ': (100, 0.04037141703673799, 0.04399472063352398),\n",
       " 'ESTJ': (170, 0.06863140896245458, 0.07479102507699076),\n",
       " 'ENFP': (107, 0.04319741622930965, 0.047074351077870655),\n",
       " 'ISFP': (151, 0.060960839725474364, 0.0664320281566212),\n",
       " 'ENTJ': (119, 0.04804198627371821, 0.052353717553893536),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## big 5 distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SLUAN': (20, 0.008074283407347598, 0.020060180541624874),\n",
       " 'RCUAI': (25, 0.010092854259184497, 0.025075225677031094),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408),\n",
       " 'SLUEN': (47, 0.018974566007266856, 0.04714142427281846),\n",
       " 'RLOEI': (26, 0.010496568429551878, 0.026078234704112337),\n",
       " 'RLOEN': (22, 0.008881711748082357, 0.022066198595787363),\n",
       " 'RCUEN': (18, 0.0072668550666128385, 0.01805416248746239),\n",
       " 'SCUAI': (46, 0.018570851836899476, 0.04613841524573721),\n",
       " 'RLUAI': (28, 0.011303996770286637, 0.028084252758274825),\n",
       " 'RCOEI': (47, 0.018974566007266856, 0.04714142427281846),\n",
       " 'RLOAI': (34, 0.013726281792490917, 0.034102306920762285),\n",
       " 'RLUAN': (33, 0.013322567622123537, 0.033099297893681046),\n",
       " 'RCOAN': (54, 0.021800565199838515, 0.05416248746238716),\n",
       " 'SLUAI': (28, 0.011303996770286637, 0.028084252758274825),\n",
       " 'SCUEI': (42, 0.016955995155429955, 0.04212637913741224),\n",
       " 'SCOEN': (24, 0.009689140088817117, 0.024072216649949848),\n",
       " 'SCUAN': (31, 0.012515139281388777, 0.031093279839518557),\n",
       " 'SCOAN': (38, 0.015341138473960436, 0.03811434302908726),\n",
       " 'SLOEN': (32, 0.012918853451756156, 0.0320962888665998),\n",
       " 'RLUEN': (23, 0.009285425918449738, 0.023069207622868605),\n",
       " 'SCOAI': (40, 0.016148566814695196, 0.04012036108324975),\n",
       " 'SLOAN': (13, 0.005248284214775939, 0.013039117352056168),\n",
       " 'RCUEI': (20, 0.008074283407347598, 0.020060180541624874),\n",
       " 'RCOAI': (60, 0.024222850222042795, 0.06018054162487462),\n",
       " 'SCOEI': (44, 0.017763423496164714, 0.044132397191574725),\n",
       " 'RLUEI': (27, 0.010900282599919257, 0.02708124373119358),\n",
       " 'SLOAI': (12, 0.004844570044408559, 0.012036108324974924),\n",
       " 'RCOEN': (39, 0.015744852644327817, 0.03911735205616851),\n",
       " 'SCUEN': (32, 0.012918853451756156, 0.0320962888665998),\n",
       " 'RLOAN': (21, 0.008477997577714978, 0.02106318956870612),\n",
       " 'SLOEI': (21, 0.008477997577714978, 0.02106318956870612),\n",
       " 'SLUEI': (29, 0.011707710940654016, 0.029087261785356068),\n",
       " 'RCUAN': (21, 0.008477997577714978, 0.02106318956870612)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mbpt dimension distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### introversion vs. extraversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': (1158, 0.46750100928542593, 0.5094588649362076),\n",
       " 'I': (1115, 0.4501412999596286, 0.4905411350637923),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[0] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sensing vs. intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': (1348, 0.5442067016552281, 0.5930488341399032),\n",
       " 'N': (925, 0.3734356075898264, 0.4069511658600968),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[1] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thinking vs. feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': (1051, 0.42430359305611626, 0.462384513858337),\n",
       " 'T': (1222, 0.4933387161889382, 0.537615486141663),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[2] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### judging vs. perceiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J': (1098, 0.44327815906338314, 0.48306203255609326),\n",
       " 'P': (1175, 0.4743641501816714, 0.5169379674439067),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[3] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## big 5 dimension distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### social vs. reserved (extraversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': (499, 0.20145337101332256, 0.5005015045135406),\n",
       " 'R': (498, 0.2010496568429552, 0.49949849548645936),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[0] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### limbic vs. calm (neuroticism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': (416, 0.16794509487283005, 0.4172517552657974),\n",
       " 'C': (581, 0.2345579329834477, 0.5827482447342026),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[1] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organized vs. unstructured (conscientiousness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U': (470, 0.18974566007266855, 0.47141424272818455),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408),\n",
       " 'O': (527, 0.2127573677836092, 0.5285857572718154)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[2] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agreeable vs. egocentric (agreeableness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': (504, 0.20347194186515946, 0.5055165496489469),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408),\n",
       " 'E': (493, 0.1990310859911183, 0.4944834503510532)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[3] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inquisitive vs. non-curious (openness to experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': (468, 0.1889382317319338, 0.46940822467402205),\n",
       " 'I': (529, 0.21356479612434395, 0.5305917753259779),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[4] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mbpt alternate dimension distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### introversion vs. extraversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E': (1156, 0.46669358094469116, 0.5085789705235372),\n",
       " 'I': (1117, 0.45094872830036337, 0.4914210294764628),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[0] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sensing vs. intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': (1356, 0.5474364150181671, 0.5965684117905852),\n",
       " 'N': (917, 0.3702058942268874, 0.4034315882094149),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[1] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thinking vs. feeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F': (1046, 0.4222850222042794, 0.4601847778266608),\n",
       " 'T': (1227, 0.49535728704077514, 0.5398152221733392),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[2] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### judging vs. perceiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'J': (1095, 0.442067016552281, 0.48174219093708753),\n",
       " 'P': (1178, 0.47557529269277354, 0.5182578090629124),\n",
       " None: (204, 0.08235769075494549, 0.08974923009238892)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbpt_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.MBPT)\n",
    "    mbpt_dist[label[3] if label else label] += 1\n",
    "\n",
    "total_count = sum(mbpt_dist.values())\n",
    "valid_count = sum([mbpt_dist[key] for key in mbpt_dist if key])\n",
    "{key: (mbpt_dist[key], mbpt_dist[key] / total_count, mbpt_dist[key] / valid_count) for key in  mbpt_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## big 5 alternate dimension distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### social vs. reserved (extraversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': (501, 0.20226079935405733, 0.5025075225677031),\n",
       " 'R': (496, 0.20024222850222043, 0.4974924774322969),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[0] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### limbic vs. calm (neuroticism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': (419, 0.16915623738393218, 0.4202607823470411),\n",
       " 'C': (578, 0.23334679047234558, 0.5797392176529589),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[1] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organized vs. unstructured (conscientiousness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U': (474, 0.19136051675413807, 0.4754262788365095),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408),\n",
       " 'O': (523, 0.2111425111021397, 0.5245737211634904)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[2] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### agreeable vs. egocentric (agreeableness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': (507, 0.20468308437626162, 0.5085255767301906),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408),\n",
       " 'E': (490, 0.19781994348001614, 0.49147442326980945)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[3] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inquisitive vs. non-curious (openness to experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': (470, 0.18974566007266855, 0.47141424272818455),\n",
       " 'I': (527, 0.2127573677836092, 0.5285857572718154),\n",
       " None: (1480, 0.5974969721437222, 1.4844533600802408)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "big5_dist = Counter()\n",
    "\n",
    "for row in char_pers.iloc:\n",
    "    label = pers_labels.get_alt_dim_labels(row, pers_labels.BIG_5)\n",
    "    big5_dist[label[4] if label else label] += 1\n",
    "\n",
    "total_count = sum(big5_dist.values())\n",
    "valid_count = sum([big5_dist[key] for key in big5_dist if key])\n",
    "{key: (big5_dist[key], big5_dist[key] / total_count, big5_dist[key] / valid_count) for key in  big5_dist}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
