{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from data_processing import pers_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = os.environ[\"WORKSPACE_PATH\"]\n",
    "\n",
    "data_type = \"mbpt_0_top_lbl\"\n",
    "\n",
    "label_mode = pers_labels.MBPT if pers_labels.MBPT.lower() in data_type else pers_labels.BIG_5\n",
    "\n",
    "index = [idx for idx in range(5) if str(idx) in data_type][0]\n",
    "\n",
    "pers_defs = {\n",
    "    pers_labels.MBPT: {\n",
    "        0: ((\"I\", \"introverted\"), (\"E\", \"extroverted\")),\n",
    "        1: ((\"S\", \"sensing\"), (\"N\", \"intuitive\")),\n",
    "        2: ((\"F\", \"feeling\"), (\"T\", \"thinking\")),\n",
    "        3: ((\"J\", \"judging\"), (\"P\", \"perceiving\")),\n",
    "    },\n",
    "    pers_labels.BIG_5: {\n",
    "        0: ((\"S\", \"social\"), (\"R\", \"reserved\")),\n",
    "        1: ((\"L\", \"limbic\"), (\"C\", \"calm\")),\n",
    "        2: ((\"O\", \"organized\"), (\"U\", \"unstructured\")),\n",
    "        3: ((\"A\", \"agreeable\"), (\"E\", \"egocentric\")),\n",
    "        4: ((\"N\", \"non-curious\"), (\"I\", \"inquisitive\")),\n",
    "    }\n",
    "}\n",
    "\n",
    "((label1, label1_def), (label2, label2_def)) = pers_defs[label_mode][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PWD}/data/cornell_movies/speakers.json\", \"r+\") as fp:\n",
    "    fp_parsed = json.load(fp)\n",
    "    chars_meta = {}\n",
    "    chars_meta_rows = []\n",
    "    for char in fp_parsed:\n",
    "        meta = fp_parsed[char][\"meta\"]\n",
    "        meta[\"character_name\"] = meta[\"character_name\"].lower()\n",
    "        meta[\"char_id\"] = char\n",
    "        chars_meta[char] = meta\n",
    "        chars_meta_rows.append(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1932"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(f\"{PWD}/data/model_datasets/{data_type}.jsonl\", lines=True)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text, char):\n",
    "    _, scene = text.split(\"\\n\", 1)\n",
    "\n",
    "    return f\"\"\"\n",
    "    Read the scenes below and then categorize {char}'s personality as {label1} for {label1_def} or \"{label2}\" for {label2_def}, according to the {label_mode.lower()} personality typology. Response with only one word.\n",
    "\n",
    "    scenes:\n",
    "    {scene}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for row in dataset.iloc:\n",
    "    char_name = chars_meta[row.char_id][\"character_name\"]\n",
    "    scene = row.text\n",
    "    prompts.append(create_prompt(scene, char_name))\n",
    "\n",
    "dataset[\"prompt\"] = prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_messages(df):\n",
    "    messages = []\n",
    "    df.to_dict(orient=\"records\")\n",
    "    for row in df.iloc:\n",
    "        messages.append(([{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": row.prompt\n",
    "        }], row.label))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = to_messages(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation time!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/neigbe/miniconda3/envs/personality/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a5bc8671e142fcba1a2010ce54c0b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/neigbe/miniconda3/envs/personality/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a2c8cf96da4dba860e7e29fb315e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/59.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13e978d8aa44d1c81f075f6328d6801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27628c1539a4d18b2cfcfff9fdc90dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00030.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb490ad5ed2048a28795b498ac0639b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3283d46ec9ec4217bdd2c5d9585aceb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cdf7ddf2cd454f908cc96f4e7b4e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2390c612ce446c9cb362d8781a2bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aca744a9b84ec29f9e8887b4fd2bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf29e2071df4749b09a63666703dce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b18d335d6a47c3bfffe5164b1e2d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12d42a04b4143bbbcbfcc0d5465911f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c353a86567f445ea2ccb70f96e2381e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4247df55c06414492449cb224e134ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7e9b0e31874dc3996857fd614fe3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce94b9b032140d29d2b90a794a0ca16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851d70a1681748638f9d24dae73615de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da493799ec514d79b063e40e9e3a28c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92bb5a75fc742c4a299d6ffe182a836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fda108da20f47db804788f6e30149e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f25e0ec00f44627bfe13e582d17b7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb6059681f0497fbd83323bf616b3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "564e86783c5642b481373aa3458a0337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cbe001b4354d9ab8c2074a1c38729c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5829b397cf6f42088ad6928f7e44b224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ccf4d6f103a4e0e9089e30e27f9fc34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8df50b02f442538ddf9b6497dd2f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a0039f51754c268bcf9f14253472b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a7a3461f474a44a928533ba338c6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e806f63cbeb410eb6283bf0597ccc1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c38d89a2fa5445eba3aa5c22dde2c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaea155af6594d9e97f15b7d66374556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793ea3daf53e47ff825e8b1919d179dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00030.safetensors:   0%|          | 0.00/2.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bad4074a5cb42769d6ebe5076c35fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ae611e85de47e59e0f68c305b16f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-70B-Instruct\"\n",
    "\n",
    "tkr = AutoTokenizer.from_pretrained(model_id)\n",
    "# tkr.add_special_tokens({'pad_token': '[PAD]'})\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    cache_dir=\"/nlp/scr/neigbe/.cache\")\n",
    "\n",
    "model.generation_config.pad_token_ids = tkr.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "for msg, lbl in tqdm(messages):\n",
    "    input_ids = tkr.apply_chat_template(msg, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "    terminators = [tkr.eos_token_id, tkr.convert_tokens_to_ids(\"<|eot_id|>\")]\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    preds.append(tkr.decode(response, skip_special_tokens=True))\n",
    "    labels.append(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"{PWD}/model_preds/llama-70b-zero-shot.jsonl\", \"w+\") as fp:\n",
    "    for pdt, lbl in zip(preds, labels):\n",
    "        fp.write(json.dumps({\"pred\": pdt, \"label\": lbl}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_preds = []\n",
    "filt_labels = []\n",
    "\n",
    "for pdt, lb in zip(preds, labels):\n",
    "    if pdt in [\"E\", \"I\"]:\n",
    "        filt_preds.append(pdt)\n",
    "        filt_labels.append(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "\n",
    "final_labels = label_enc.fit_transform(filt_labels)\n",
    "final_preds = label_enc.transform(filt_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overall metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.6016322013970538, 'recall': 0.6235828993691643, 'precision': 0.6525918886278064}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "args = {\"predictions\": final_preds,  \"references\": final_labels, \"average\": \"macro\"}\n",
    "f1 = evaluate.load(\"f1\")\n",
    "acc = evaluate.load(\"recall\")\n",
    "prec = evaluate.load(\"precision\")\n",
    "\n",
    "scores = {}\n",
    "scores.update(f1.compute(**args))\n",
    "scores.update(acc.compute(**args))\n",
    "scores.update(prec.compute(**args))\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per class metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_43b5b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_43b5b_level0_col0\" class=\"col_heading level0 col0\" >label</th>\n",
       "      <th id=\"T_43b5b_level0_col1\" class=\"col_heading level0 col1\" >f1</th>\n",
       "      <th id=\"T_43b5b_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_43b5b_level0_col3\" class=\"col_heading level0 col3\" >precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_43b5b_row0_col0\" class=\"data row0 col0\" >E</td>\n",
       "      <td id=\"T_43b5b_row0_col1\" class=\"data row0 col1\" >0.519053876478318</td>\n",
       "      <td id=\"T_43b5b_row0_col2\" class=\"data row0 col2\" >0.4026503567787971</td>\n",
       "      <td id=\"T_43b5b_row0_col3\" class=\"data row0 col3\" >0.7301293900184843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_43b5b_row1_col0\" class=\"data row1 col0\" >I</td>\n",
       "      <td id=\"T_43b5b_row1_col1\" class=\"data row1 col1\" >0.6842105263157895</td>\n",
       "      <td id=\"T_43b5b_row1_col2\" class=\"data row1 col2\" >0.8445154419595314</td>\n",
       "      <td id=\"T_43b5b_row1_col3\" class=\"data row1 col3\" >0.5750543872371283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbfe428d040>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\"predictions\": final_preds,  \"references\": final_labels, \"average\": None}\n",
    "scores = {}\n",
    "scores.update(f1.compute(**args))\n",
    "scores.update(acc.compute(**args))\n",
    "scores.update(prec.compute(**args))\n",
    "\n",
    "\n",
    "class_scores = np.concatenate([val.reshape(-1, 1) for val in scores.values()], axis=1)\n",
    "\n",
    "class_names = np.array(label_enc.inverse_transform(range(2))).reshape(-1, 1)\n",
    "per_class_df = pd.DataFrame(np.concatenate([class_names, class_scores], axis=1), columns=[\"label\", *scores.keys()])\n",
    "\n",
    "per_class_df.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
