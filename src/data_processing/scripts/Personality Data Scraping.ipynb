{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests as r\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logger with 'spam_application'\n",
    "logger = logging.getLogger('pdb_scraper')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD = os.environ[\"WORKSPACE_PATH\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERS_DATA_FOLDER = f\"{PWD}/data/personality_data/\"\n",
    "\n",
    "in_pers_data = lambda data_path: f\"{PERS_DATA_FOLDER}{data_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_request(url):\n",
    "    try:\n",
    "        resp = r.get(url)\n",
    "        return resp.json()\n",
    "    except:\n",
    "        raise Exception(f\"Error in HTTP request: {resp.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_load_json(path, lines=False):\n",
    "    obj = [] if lines else {}\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r+\") as fp:\n",
    "            if lines:\n",
    "                obj += [json.loads(line) for line in fp.readlines()]\n",
    "            else:\n",
    "                obj.update(json.load(fp))\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(path, obj, lines=False):\n",
    "    with open(path, \"w+\") as fp:\n",
    "        if lines:\n",
    "            fp.writelines([json.dumps(item) for item in obj])\n",
    "        else:\n",
    "            json.dump(obj, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PWD}/data/cornell_movies/speakers.json\", \"r+\") as  fp:\n",
    "    speakers = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting movie pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = sorted(list({speakers[char][\"meta\"][\"movie_name\"].strip().lower() for char in speakers}))\n",
    "\n",
    "movie_to_id_path = in_pers_data(\"movie_to_id.json\")\n",
    "movie_name_clarify_path = in_pers_data(\"movie_name_clarifications.json\")\n",
    "movie_cat_excepts_path = in_pers_data(\"movie_category_exceptions.json\")\n",
    "\n",
    "movie_to_id = open_and_load_json(movie_to_id_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_movie(movie: str, cat_id=3) -> int:\n",
    "    req = f\"https://api.personality-database.com/api/v2/search/subcategories?query={'%20'.join(movie.split())}&limt=1000&nextCursor=0\"\n",
    "    resp = r.get(req)\n",
    "    logger.debug(req)\n",
    "    subs = resp.json()[\"data\"][\"results\"]\n",
    "    for sub in subs:\n",
    "        site_full_name = sub[\"name\"].lower().strip().replace(\" & \", \" \")\n",
    "        site_name = re.sub(\"\\(\\d{4}\\)\", \"\", site_full_name).strip()\n",
    "        if site_name != movie and (site_full_name != movie.replace(\" - \", \"-\")) and (site_name != movie.replace(\" - \", \"-\")):\n",
    "            logger.debug(f\"\\nSkipped result for '{movie}' because name did not match ({site_name} or {site_full_name})\")\n",
    "            continue\n",
    "        if (cat_id:=sub[\"categoryID\"]) != str(cat_id):\n",
    "            logger.debug(f\"\\nSkipped result for '{movie}' because was not in movie category ({cat_id})\")\n",
    "            continue\n",
    "        if not sub[\"isFictional\"]:\n",
    "            logger.debug(f\"\\nSkipped result for '{movie}' because was not fictional\")\n",
    "            continue\n",
    "        return int(sub[\"id\"])\n",
    "    raise Exception(\"Movie not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 617/617 [00:00<00:00, 1415692.32it/s]\n"
     ]
    }
   ],
   "source": [
    "movie_name_clarify = open_and_load_json(movie_name_clarify_path)\n",
    "movie_cat_excepts = open_and_load_json(movie_cat_excepts_path)\n",
    "\n",
    "found = 0\n",
    "missing = 0\n",
    "for mov in tqdm.tqdm(movies):\n",
    "    if mov in movie_to_id:\n",
    "        continue\n",
    "    try:\n",
    "        if mov in movie_name_clarify and not movie_name_clarify[mov]:\n",
    "            continue\n",
    "        movie_to_id[mov] = find_movie(movie_name_clarify.get(mov, mov), cat_id=movie_cat_excepts.get(mov, 3))\n",
    "        found += 1\n",
    "    except Exception as e:\n",
    "        logger.debug(e)\n",
    "        missing += 1\n",
    "        logger.info(f\"Could not find '{mov}'\")\n",
    "        # logger.info(f\"Could not find '{mov}' ({found} found/{missing} missing)\")\n",
    "        break\n",
    "    # time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correcting name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_name = None\n",
    "movie_name_clarify[mov] = correct_name.lower() if type(correct_name) == str else correct_name\n",
    "save_json(movie_name_clarify_path, movie_name_clarify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correcting category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat = 2\n",
    "movie_cat_excepts[mov] = new_cat\n",
    "save_json(movie_cat_excepts_path, movie_cat_excepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(movie_to_id_path, movie_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting characters from movie pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_chars_path = in_pers_data(\"movie_to_chars.json\")\n",
    "movie_to_chars = open_and_load_json(movie_to_chars_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profiles(film_id: int) -> dict:\n",
    "    out = safe_request(f\"https://api.personality-database.com/api/v1/profiles?offset=0&limit=100&sub_cat_id={film_id}&cat_id=3&property_id=2\")\n",
    "    name_to_id = {prof[\"mbti_profile\"].lower(): prof[\"id\"] for prof in out[\"profiles\"]}\n",
    "    return name_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464/464 [01:15<00:00,  6.15it/s] \n"
     ]
    }
   ],
   "source": [
    "for movie in tqdm.tqdm(movie_to_id):\n",
    "    if movie in movie_to_chars:\n",
    "        continue\n",
    "    movie_to_chars[movie] = get_profiles(movie_to_id[movie])\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(movie_to_chars_path, movie_to_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matching speakers to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_id_to_pdb_id = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_match(name1, name2):\n",
    "    clean = lambda name: re.sub(\"[^A-Za-z0-9 ]\", \"\", name).lower()\n",
    "    cleaned_name1 = clean(name1)\n",
    "    cleaned_name2 = clean(name2)\n",
    "\n",
    "    strong_match = lambda n1, n2: n1 in n2\n",
    "    weak_match = lambda n1, n2: any([n1_part in n2 for n1_part in n1.split()])\n",
    "    both_ways = lambda arg1, arg2, func: func(arg1, arg2) or func(arg2, arg1)\n",
    "\n",
    "    return (both_ways(cleaned_name1, cleaned_name2, strong_match), both_ways(cleaned_name1, cleaned_name2, weak_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches = []\n",
    "all_misses = []\n",
    "near_misses = []\n",
    "\n",
    "with open(in_pers_data(\"char_name_corrections.json\"), \"r+\") as fp:\n",
    "    char_corrections = json.load(fp)\n",
    "\n",
    "for char_id in speakers:\n",
    "    char_dict = speakers[char_id][\"meta\"]\n",
    "    char_name = char_dict[\"character_name\"].lower()\n",
    "    movie = char_dict[\"movie_name\"]\n",
    "\n",
    "    if movie in movie_to_chars:\n",
    "        correct_name = char_corrections.get(char_id, char_name)\n",
    "        poss_matches = {char: name_match(correct_name, char[0]) for char in movie_to_chars[movie].items()}\n",
    "        matches = [char for char in poss_matches if poss_matches[char][0]]\n",
    "        if len(matches) == 1:\n",
    "            all_matches.append((movie, char_name, matches[0][0]))\n",
    "            char_id_to_pdb_id[char_id] = matches[0][1]\n",
    "        else:\n",
    "            poss_matches = [char for char in poss_matches if poss_matches[char][1]]\n",
    "            if poss_matches:\n",
    "                near_misses.append((movie, char_id, char_name, poss_matches))\n",
    "\n",
    "            all_misses.append((movie, char_id, char_name, movie_to_chars[movie].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting speaker profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_pers_path = in_pers_data(\"char_to_pers_votes.json\")\n",
    "\n",
    "char_pers = open_and_load_json(char_pers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_systems = {\"1\": \"Myers Briggs\", \"9\": \"SLOAN\"}\n",
    "\n",
    "def get_pers_votes(prof_id: str) -> dict:\n",
    "    votes = defaultdict(dict)\n",
    "\n",
    "    out = safe_request(f\"https://api.personality-database.com/api/v1/profile/{prof_id}\")\n",
    "\n",
    "    prof = out[\"breakdown_systems\"]\n",
    "\n",
    "    for sys_code in pers_systems:\n",
    "        for res in prof[sys_code]:\n",
    "            votes[pers_systems[sys_code]][res[\"personality_type\"]] = res[\"theCount\"]\n",
    "\n",
    "    return votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2477/2477 [20:19<00:00,  2.03it/s] \n"
     ]
    }
   ],
   "source": [
    "for char_id in tqdm.tqdm(char_id_to_pdb_id):\n",
    "    try:\n",
    "        if char_id in char_pers:\n",
    "            continue\n",
    "\n",
    "        char_pers[char_id] = get_pers_votes(char_id_to_pdb_id[char_id])\n",
    "\n",
    "        time.sleep(3)\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(char_pers_path, char_pers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
